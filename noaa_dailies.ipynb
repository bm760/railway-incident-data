{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download data:\n",
    "i was unable to find ftp login info, so this has to be done by hand ( if you find a way around it lmk) \n",
    "\n",
    "i also could not get the noaa python package to work - https://pypi.org/project/noaa-weather/\n",
    "\n",
    "the dataset we are using comes from here: https://www.ncei.noaa.gov/metadata/geoportal/rest/metadata/item/gov.noaa.ncdc:C00861/html\n",
    "\n",
    "1. you can read on the features of the library and the important files here: ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/readme.txt\n",
    "2. the main directory you will be using is ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/\n",
    "3. recommend that you download ghcnd-stations.txt, ghcnd-states.txt, and ghcnd_ghc.tar.gz  (previously ghcnd_all.tar.gz  but that is 10 times larger)\n",
    "4. this notebook deals specifically with the ghcnd_ghc.tar.gz , you will need to have the contents un-zipped into a location on your pc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/62165172/convert-dly-files-to-csv-using-python\n",
    "import glob\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# fields as given by the spec\n",
    "\n",
    "fields = [\n",
    "    [\"ID\", 1, 11],\n",
    "    [\"YEAR\", 12, 15],\n",
    "    [\"MONTH\", 16, 17],\n",
    "    [\"ELEMENT\", 18, 21]]\n",
    "\n",
    "offset = 22\n",
    "\n",
    "for value in range(1, 32):\n",
    "    fields.append((f\"VALUE{value}\", offset,     offset + 4))\n",
    "    fields.append((f\"MFLAG{value}\", offset + 5, offset + 5))\n",
    "    fields.append((f\"QFLAG{value}\", offset + 6, offset + 6))\n",
    "    fields.append((f\"SFLAG{value}\", offset + 7, offset + 7))\n",
    "    offset += 8\n",
    "\n",
    "# Modify fields to use Python numbering\n",
    "fields = [[var, start - 1, end] for var, start, end in fields]\n",
    "fieldnames = [var for var, start, end in fields]\n",
    "\n",
    "\n",
    "# the goal of this code is to make 1 file TOTAL from many (1 per station), which can then be filtered  by year. \n",
    "\n",
    "# enter where you want a csv saved - it will be many Gigs\n",
    "csv_filename = 'F:\\weather\\hcn\\ghcnd_hcn.csv'\n",
    "\n",
    "with open(csv_filename, 'w', newline='') as f_csv:\n",
    "    \n",
    "    # glob.glob should aim to where you unzipped the ghcnd_ghc.tar.gz , inside that will be ghcnd_hcn folder, which contains all the dailies\n",
    "    for dly_filename in glob.glob(r'F:\\weather\\hcn\\ghcnd_hcn\\*.dly', recursive=True): \n",
    "        path, name = os.path.split(dly_filename)\n",
    "\n",
    "        \n",
    "        # you could replace this with adding to a dataframe or something else, but i am running out of brain power.\n",
    "        with open(dly_filename, newline='') as f_dly:\n",
    "            spamwriter  = csv.writer(f_csv)\n",
    "            spamwriter.writerow(fieldnames) \n",
    "\n",
    "            for line in f_dly:\n",
    "                row = [line[start:end].strip() for var, start, end in fields]\n",
    "                spamwriter.writerow(row)\n",
    "                \n",
    "                \n",
    "# end product is a csv with us weather station data.  DEFINTELY read the readme, this dataformat is bonkers.   ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/readme.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
